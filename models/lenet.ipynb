{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN LeNet-5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary_categorical(array):\n",
    "    new_array = []\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        content = [0] * 25\n",
    "        index = np.argmax(array[i])\n",
    "        content[index] = 1\n",
    "        new_array.append(content)\n",
    "\n",
    "    return new_array\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('../dataset/sign_mnist_train.csv', delimiter=',')\n",
    "test_data = np.genfromtxt('../dataset/sign_mnist_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 784) (27455,)\n",
      "(7172, 784) (7172,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data[1:, 1:]\n",
    "y_train = train_data[1:, 0]\n",
    "\n",
    "X_test = test_data[1:, 1:]\n",
    "y_test = test_data[1:, 0]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 28, 28)\n",
      "(7172, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# normalise pixel values from 0-255 to 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# reshape 1d array of 784 to 2d array of size 28x28\n",
    "X_train = X_train.reshape(len(X_train), 28, 28)\n",
    "X_test = X_test.reshape((len(X_test)), 28, 28)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 18:45:34.005492: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(28, 28, 1), kernel_size=(5, 5), filters=6, strides=1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(kernel_size=(5, 5), filters=16, strides=1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=120, activation='relu'))\n",
    "model.add(Dense(units=84, activation='relu'))\n",
    "model.add(Dense(units=25, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation using k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687/687 [==============================] - 7s 10ms/step - loss: 1.5226 - categorical_crossentropy: 1.5226\n",
      "687/687 [==============================] - 8s 12ms/step - loss: 0.2993 - categorical_crossentropy: 0.2993\n",
      "687/687 [==============================] - 9s 12ms/step - loss: 0.0791 - categorical_crossentropy: 0.0791\n",
      "687/687 [==============================] - 8s 12ms/step - loss: 0.0289 - categorical_crossentropy: 0.0289\n",
      "687/687 [==============================] - 8s 12ms/step - loss: 0.0333 - categorical_crossentropy: 0.0333\n",
      "[0.7907484975414314, 0.9635767619741397, 0.9344381715534511, 0.9998178838098707, 0.9901657257330176]\n",
      "Average F1 Score: 0.935749408122382\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    # one-hot\n",
    "    y_train_fold = to_categorical(y_train_fold)\n",
    "    y_test_fold = to_categorical(y_test_fold)\n",
    "\n",
    "    # fit and predict\n",
    "    model.fit(x=X_train_fold, y=y_train_fold)\n",
    "    y_predicted = model.predict(x=X_test_fold)\n",
    "\n",
    "    # convert predicted float values to binary values\n",
    "    y_predicted = to_binary_categorical(y_predicted)\n",
    "    \n",
    "    # calculate score\n",
    "    score = f1_score(y_test_fold, y_predicted, average='micro')\n",
    "    f1_scores.append(score)\n",
    "\n",
    "print(f1_scores)\n",
    "print('Average F1 Score:', mean(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.8350529838259899\n"
     ]
    }
   ],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_predicted = model.predict(x=X_test)\n",
    "y_predicted = to_binary_categorical(y_predicted)\n",
    "\n",
    "score = f1_score(y_test, y_predicted, average='micro')\n",
    "print('F1 Score: ', score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
